{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the notebook that runs with open Colab, backend is GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6mOWi8Nw4Mcp",
    "outputId": "208c0862-0c2d-4785-8859-ea5077c40293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |████                            | 10kB 33.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 20kB 5.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 30kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 40kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 51kB 6.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 61kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 71kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 5.3MB/s \n",
      "\u001b[?25h  Building wheel for graspy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q graspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kms3siYy4Xi8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SinkhornKnopp:\n",
    "    def __init__(self, max_iter=1000, epsilon=1e-3):\n",
    "        if type(max_iter) is int or type(max_iter) is float:\n",
    "            if max_iter > 0:\n",
    "                self._max_iter = int(max_iter)\n",
    "            else:\n",
    "                msg = \"max_iter must be greater than 0\"\n",
    "                raise ValueError(msg)\n",
    "        else:\n",
    "            msg = \"max_iter is not of type int or float\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        if type(epsilon) is int or type(epsilon) is float:\n",
    "            if epsilon > 0 and epsilon < 1:\n",
    "                self._epsilon = int(epsilon)\n",
    "            else:\n",
    "                msg = \"epsilon must be between 0 and 1 exclusively\"\n",
    "                raise ValueError(msg)\n",
    "        else:\n",
    "            msg = \"epsilon is not of type int or float\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        self._stopping_condition = None\n",
    "        self._iterations = 0\n",
    "        self._D1 = np.ones(1)\n",
    "        self._D2 = np.ones(1)\n",
    "\n",
    "    def fit(self, P):\n",
    "        \"\"\"\n",
    "        Fit the diagonal matrices in Sinkhorn Knopp's algorithm\n",
    "        Parameters\n",
    "        ----------\n",
    "        P : 2d array-like\n",
    "            Must be a square non-negative 2d array-like object, that\n",
    "            is convertible to a numpy array. The matrix must not be\n",
    "            equal to 0 and it must have total support for the algorithm\n",
    "            to converge.\n",
    "        Returns\n",
    "        -------\n",
    "        P_eps : A double stochastic matrix.\n",
    "        \"\"\"\n",
    "        P = np.asarray(P)\n",
    "        assert np.all(P >= 0)\n",
    "        assert P.ndim == 2\n",
    "        assert P.shape[0] == P.shape[1]\n",
    "\n",
    "        N = P.shape[0]\n",
    "        max_thresh = 1 + self._epsilon\n",
    "        min_thresh = 1 - self._epsilon\n",
    "\n",
    "        # Initialize r and c, the diagonals of D1 and D2\n",
    "        # and warn if the matrix does not have support.\n",
    "        r = np.ones((N, 1))\n",
    "        pdotr = P.T.dot(r)\n",
    "        total_support_warning_str = (\n",
    "            \"Matrix P must have total support. \" \"See documentation\"\n",
    "        )\n",
    "        if not np.all(pdotr != 0):\n",
    "            warnings.warn(total_support_warning_str, UserWarning)\n",
    "\n",
    "        c = 1 / pdotr\n",
    "        pdotc = P.dot(c)\n",
    "        if not np.all(pdotc != 0):\n",
    "            warnings.warn(total_support_warning_str, UserWarning)\n",
    "\n",
    "        r = 1 / pdotc\n",
    "        del pdotr, pdotc\n",
    "\n",
    "        P_eps = np.copy(P)\n",
    "        while (\n",
    "            np.any(np.sum(P_eps, axis=1) < min_thresh)\n",
    "            or np.any(np.sum(P_eps, axis=1) > max_thresh)\n",
    "            or np.any(np.sum(P_eps, axis=0) < min_thresh)\n",
    "            or np.any(np.sum(P_eps, axis=0) > max_thresh)\n",
    "        ):\n",
    "\n",
    "            c = 1 / P.T.dot(r)\n",
    "            r = 1 / P.dot(c)\n",
    "\n",
    "            self._D1 = np.diag(np.squeeze(r))\n",
    "            self._D2 = np.diag(np.squeeze(c))\n",
    "            P_eps = self._D1.dot(P).dot(self._D2)\n",
    "\n",
    "            self._iterations += 1\n",
    "\n",
    "            if self._iterations >= self._max_iter:\n",
    "                self._stopping_condition = \"max_iter\"\n",
    "                break\n",
    "\n",
    "        if not self._stopping_condition:\n",
    "            self._stopping_condition = \"epsilon\"\n",
    "\n",
    "        self._D1 = np.diag(np.squeeze(r))\n",
    "        self._D2 = np.diag(np.squeeze(c))\n",
    "        P_eps = self._D1.dot(P).dot(self._D2)\n",
    "\n",
    "        return P_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "VFlTnR5t3n1l",
    "outputId": "6dfeeec5-95ce-4da0-b9e6-a0883418383d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import graspy\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.utils import check_array\n",
    "#from skp import SinkhornKnopp\n",
    "from joblib import Parallel, delayed\n",
    "from graspy.simulations import er_np\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bu9GC9Q3n1q"
   },
   "outputs": [],
   "source": [
    "n = 500\n",
    "p = 0.3\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-9TzGS23n1t",
    "outputId": "bd6bac5c-e5cc-41be-d69f-bbadc9bb5d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:00:00.000061\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "print ('running time', dt.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHv0ZAif3n1x"
   },
   "source": [
    "# from Ali's codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlqYP77DHvDW"
   },
   "outputs": [],
   "source": [
    "class FastApproximateQAP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_init=2,\n",
    "        init_method=\"barycenter\",\n",
    "        max_iter=30,\n",
    "        shuffle_input=True,\n",
    "        eps=0.1,\n",
    "        gmp=False,\n",
    "    ):\n",
    "\n",
    "        if n_init > 0 and type(n_init) is int:\n",
    "            self.n_init = n_init\n",
    "        else:\n",
    "            msg = '\"n_init\" must be a positive integer'\n",
    "            raise TypeError(msg)\n",
    "        if init_method == \"rand\":\n",
    "            self.init_method = \"rand\"\n",
    "        elif init_method == \"barycenter\":\n",
    "            self.init_method = \"barycenter\"\n",
    "            self.n_init = 1\n",
    "        else:\n",
    "            msg = 'Invalid \"init_method\" parameter string'\n",
    "            raise ValueError(msg)\n",
    "        if max_iter > 0 and type(max_iter) is int:\n",
    "            self.max_iter = max_iter\n",
    "        else:\n",
    "            msg = '\"max_iter\" must be a positive integer'\n",
    "            raise TypeError(msg)\n",
    "        if type(shuffle_input) is bool:\n",
    "            self.shuffle_input = shuffle_input\n",
    "        else:\n",
    "            msg = '\"shuffle_input\" must be a boolean'\n",
    "            raise TypeError(msg)\n",
    "        if eps > 0 and type(eps) is float:\n",
    "            self.eps = eps\n",
    "        else:\n",
    "            msg = '\"eps\" must be a positive float'\n",
    "            raise TypeError(msg)\n",
    "        if type(gmp) is bool:\n",
    "            self.gmp = gmp\n",
    "        else:\n",
    "            msg = '\"gmp\" must be a boolean'\n",
    "            raise TypeError(msg)\n",
    "\n",
    "    def fit(self, A, B):\n",
    "        A = check_array(A, copy=True, ensure_2d=True)\n",
    "        B = check_array(B, copy=True, ensure_2d=True)\n",
    "\n",
    "        if A.shape[0] != B.shape[0]:\n",
    "            msg = \"Matrix entries must be of equal size\"\n",
    "            raise ValueError(msg)\n",
    "        elif A.shape[0] != A.shape[1] or B.shape[0] != B.shape[1]:\n",
    "            msg = \"Matrix entries must be square\"\n",
    "            raise ValueError(msg)\n",
    "        elif (A >= 0).all() == False or (B >= 0).all() == False:\n",
    "            msg = \"Matrix entries must be greater than or equal to zero\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        n = A.shape[0]  # number of vertices in graphs\n",
    "\n",
    "        if self.shuffle_input:\n",
    "            node_shuffle_input = np.random.permutation(n)\n",
    "            A = A[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "            # shuffle_input to avoid results from inputs that were already matched\n",
    "\n",
    "        obj_func_scalar = 1\n",
    "        if self.gmp:\n",
    "            obj_func_scalar = -1\n",
    "\n",
    "        At = np.transpose(A)  # A transpose\n",
    "        Bt = np.transpose(B)  # B transpose\n",
    "        score = math.inf\n",
    "        perm_inds = np.zeros(n)\n",
    "\n",
    "        for i in range(self.n_init):\n",
    "\n",
    "            # setting initialization matrix\n",
    "            if self.init_method == \"rand\":\n",
    "                sk = SinkhornKnopp()\n",
    "                K = np.random.rand(\n",
    "                    n, n\n",
    "                )  # generate a nxn matrix where each entry is a random integer [0,1]\n",
    "                for i in range(10):  # perform 10 iterations of Sinkhorn balancing\n",
    "                    K = sk.fit(K)\n",
    "                J = np.ones((n, n)) / float(\n",
    "                    n\n",
    "                )  # initialize J, a doubly stochastic barycenter\n",
    "                P = (K + J) / 2\n",
    "            elif self.init_method == \"barycenter\":\n",
    "                P = np.ones((n, n)) / float(n)\n",
    "\n",
    "            grad_P = math.inf  # gradient of P\n",
    "            n_iter = 0  # number of FW iterations\n",
    "\n",
    "            # OPTIMIZATION WHILE LOOP BEGINS\n",
    "            while grad_P > self.eps and n_iter < self.max_iter:\n",
    "\n",
    "                delta_f = (\n",
    "                    A @ P @ Bt + At @ P @ B\n",
    "                )  # computing the gradient of f(P) = -tr(APB^tP^t)\n",
    "                rows, cols = linear_sum_assignment(\n",
    "                    obj_func_scalar * delta_f\n",
    "                )  # run hungarian algorithm on gradient(f(P))\n",
    "                Q = np.zeros((n, n))\n",
    "                Q[rows, cols] = 1  # initialize search direction matrix Q\n",
    "\n",
    "                def f(x):  # computing the original optimization function\n",
    "                    return obj_func_scalar * np.trace(\n",
    "                        At\n",
    "                        @ (x * P + (1 - x) * Q)\n",
    "                        @ B\n",
    "                        @ np.transpose(x * P + (1 - x) * Q)\n",
    "                    )\n",
    "\n",
    "                alpha = minimize_scalar(\n",
    "                    f, bounds=(0, 1), method=\"bounded\"\n",
    "                ).x  # computing the step size                \n",
    "\n",
    "                P_1 = alpha * P + (1 - alpha) * Q  # Update P\n",
    "                grad_P = np.linalg.norm(P - P_1)\n",
    "                P = P_1\n",
    "                n_iter += 1\n",
    "            # end of FW optimization loop\n",
    "\n",
    "            _, perm_inds_new = linear_sum_assignment(\n",
    "                -P\n",
    "            )  # Project onto the set of permutation matrices\n",
    "\n",
    "            score_new = np.trace(\n",
    "                np.transpose(A) @ B[np.ix_(perm_inds_new, perm_inds_new)]\n",
    "            )  # computing objective function value\n",
    "\n",
    "            if score_new < score:  # minimizing\n",
    "                score = score_new\n",
    "                if self.shuffle_input:\n",
    "                    perm_inds = np.array([0] * n)\n",
    "                    perm_inds[node_shuffle_input] = perm_inds_new\n",
    "                else:\n",
    "                    perm_inds = perm_inds_new\n",
    "\n",
    "        if self.shuffle_input:\n",
    "            node_unshuffle_input = np.array(range(n))\n",
    "            node_unshuffle_input[node_shuffle_input] = np.array(range(n))\n",
    "            A = A[np.ix_(node_unshuffle_input, node_unshuffle_input)]\n",
    "            score = np.trace(np.transpose(A) @ B[np.ix_(perm_inds, perm_inds)])\n",
    "\n",
    "        self.perm_inds_ = perm_inds  # permutation indices\n",
    "        self.score_ = score  # objective function value\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, A, B):\n",
    "        self.fit(A, B)\n",
    "        return self.perm_inds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLCocl8S3n1x",
    "outputId": "8470a5a3-5bff-4901-94c8-5f184d725eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:01:08.789331\n",
      "Number of edge disagreements:  87272.0\n"
     ]
    }
   ],
   "source": [
    "#from faq import FastApproximateQAP\n",
    "\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)\n",
    "\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "G2 = G1[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "\n",
    "start = dt.datetime.now()\n",
    "gmp = FastApproximateQAP(n_init=10,init_method=\"rand\",gmp=True)\n",
    "gmp = gmp.fit(G1,G2)\n",
    "G2 = G2[np.ix_(gmp.perm_inds_, gmp.perm_inds_)]\n",
    "print ('running time', dt.datetime.now() - start)\n",
    "\n",
    "print(\"Number of edge disagreements: \", sum(sum(abs(G1-G2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "H2RFWxQu3n10",
    "outputId": "c6005cd1-150b-4e7e-816a-3c449ad3418e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:34:55.938386\n",
      "Number of edge disagreements:  87324.0\n"
     ]
    }
   ],
   "source": [
    "#from faq import FastApproximateQAP\n",
    "\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)\n",
    "\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "G2 = G1[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "\n",
    "start = dt.datetime.now()\n",
    "gmp = FastApproximateQAP(n_init=80,init_method=\"rand\",gmp=True)\n",
    "gmp = gmp.fit(G1,G2)\n",
    "G2 = G2[np.ix_(gmp.perm_inds_, gmp.perm_inds_)]\n",
    "print ('running time', dt.datetime.now() - start)\n",
    "\n",
    "print(\"Number of edge disagreements: \", sum(sum(abs(G1-G2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5OXUO-w3n16"
   },
   "source": [
    "# after adding parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HlEmyDJ37wG"
   },
   "outputs": [],
   "source": [
    "class FastApproximateQAP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_init=10,\n",
    "        init_method=\"rand\",\n",
    "        max_iter=30,\n",
    "        shuffle_input=True,\n",
    "        eps=0.1,\n",
    "        gmp=False,\n",
    "    ):\n",
    "\n",
    "        if n_init > 0 and type(n_init) is int:\n",
    "            self.n_init = n_init\n",
    "        else:\n",
    "            msg = '\"n_init\" must be a positive integer'\n",
    "            raise TypeError(msg)\n",
    "        if init_method == \"rand\":\n",
    "            self.init_method = \"rand\"\n",
    "        elif init_method == \"barycenter\":\n",
    "            self.init_method = \"barycenter\"\n",
    "            self.n_init = 1\n",
    "        else:\n",
    "            msg = 'Invalid \"init_method\" parameter string'\n",
    "            raise ValueError(msg)\n",
    "        if max_iter > 0 and type(max_iter) is int:\n",
    "            self.max_iter = max_iter\n",
    "        else:\n",
    "            msg = '\"max_iter\" must be a positive integer'\n",
    "            raise TypeError(msg)\n",
    "        if type(shuffle_input) is bool:\n",
    "            self.shuffle_input = shuffle_input\n",
    "        else:\n",
    "            msg = '\"shuffle_input\" must be a boolean'\n",
    "            raise TypeError(msg)\n",
    "        if eps > 0 and type(eps) is float:\n",
    "            self.eps = eps\n",
    "        else:\n",
    "            msg = '\"eps\" must be a positive float'\n",
    "            raise TypeError(msg)\n",
    "        if type(gmp) is bool:\n",
    "            self.gmp = gmp\n",
    "        else:\n",
    "            msg = '\"gmp\" must be a boolean'\n",
    "            raise TypeError(msg)\n",
    "\n",
    "    def fit(self, A, B):\n",
    "        A = check_array(A, copy=True, ensure_2d=True)\n",
    "        B = check_array(B, copy=True, ensure_2d=True)\n",
    "\n",
    "        if A.shape[0] != B.shape[0]:\n",
    "            msg = \"Matrix entries must be of equal size\"\n",
    "            raise ValueError(msg)\n",
    "        elif A.shape[0] != A.shape[1] or B.shape[0] != B.shape[1]:\n",
    "            msg = \"Matrix entries must be square\"\n",
    "            raise ValueError(msg)\n",
    "        elif (A >= 0).all() == False or (B >= 0).all() == False:\n",
    "            msg = \"Matrix entries must be greater than or equal to zero\"\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        n = A.shape[0]  # number of vertices in graphs\n",
    "\n",
    "        if self.shuffle_input:\n",
    "            node_shuffle_input = np.random.permutation(n)\n",
    "            A = A[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "            # shuffle_input to avoid results from inputs that were already matched\n",
    "\n",
    "        obj_func_scalar = 1\n",
    "        if self.gmp:\n",
    "            obj_func_scalar = -1\n",
    "\n",
    "        At = np.transpose(A)  # A transpose\n",
    "        Bt = np.transpose(B)  # B transpose\n",
    "        score = math.inf\n",
    "        perm_inds = np.zeros(n)\n",
    "\n",
    "#        for i in range(self.n_init):\n",
    "        def forloop(init_num):\n",
    "            \n",
    "            # setting initialization matrix\n",
    "            if self.init_method == \"rand\":\n",
    "                sk = SinkhornKnopp()\n",
    "                K = np.random.rand(\n",
    "                    n, n\n",
    "                )  # generate a nxn matrix where each entry is a random integer [0,1]\n",
    "                for i in range(10):  # perform 10 iterations of Sinkhorn balancing\n",
    "                    K = sk.fit(K)\n",
    "                J = np.ones((n, n)) / float(\n",
    "                    n\n",
    "                )  # initialize J, a doubly stochastic barycenter\n",
    "                P = (K + J) / 2\n",
    "            elif self.init_method == \"barycenter\":\n",
    "                P = np.ones((n, n)) / float(n)\n",
    "\n",
    "            grad_P = math.inf  # gradient of P\n",
    "            n_iter = 0  # number of FW iterations\n",
    "            \n",
    "            # OPTIMIZATION WHILE LOOP BEGINS\n",
    "            while grad_P > self.eps and n_iter < self.max_iter:\n",
    "\n",
    "                delta_f = (\n",
    "                    A @ P @ Bt + At @ P @ B\n",
    "                )  # computing the gradient of f(P) = -tr(APB^tP^t)\n",
    "                rows, cols = linear_sum_assignment(\n",
    "                    obj_func_scalar * delta_f\n",
    "                )  # run hungarian algorithm on gradient(f(P))\n",
    "                Q = np.zeros((n, n))\n",
    "                Q[rows, cols] = 1  # initialize search direction matrix Q\n",
    "\n",
    "                def f(x):  # computing the original optimization function\n",
    "                    return obj_func_scalar * np.trace(\n",
    "                        At\n",
    "                        @ (x * P + (1 - x) * Q)\n",
    "                        @ B\n",
    "                        @ np.transpose(x * P + (1 - x) * Q)\n",
    "                    )\n",
    "\n",
    "                alpha = minimize_scalar(\n",
    "                    f, bounds=(0, 1), method=\"bounded\"\n",
    "                ).x  # computing the step size\n",
    "                \n",
    "                P_1 = alpha * P + (1 - alpha) * Q  # Update P\n",
    "                grad_P = np.linalg.norm(P - P_1)\n",
    "                P = P_1\n",
    "                n_iter += 1\n",
    "            # end of FW optimization loop\n",
    "\n",
    "            _, perm_inds_new = linear_sum_assignment(\n",
    "                -P\n",
    "            )  # Project onto the set of permutation matrices\n",
    "\n",
    "            score_new = np.trace(\n",
    "                np.transpose(A) @ B[np.ix_(perm_inds_new, perm_inds_new)]\n",
    "            )  # computing objective function value\n",
    "\n",
    "            return score_new, perm_inds_new\n",
    "        if self.init_method=='barycenter':\n",
    "            self.n_init=1\n",
    "            result=forloop(self.n_init)\n",
    "        else:\n",
    "            par = Parallel(n_jobs=5)\n",
    "            result = par(delayed(forloop)(init_num) for init_num in range(self.n_init))\n",
    "        result = np.mat(result)\n",
    "        score_new = np.transpose(result[:,0])\n",
    "        perm_inds_new = result[:,1].tolist()\n",
    "        #print(score_new)\n",
    "        #print(perm_inds_new)\n",
    "\n",
    "        _, column = score_new.shape# get the matrix of a raw and column\n",
    "        _positon = np.argmin(score_new)# get the index of max in the a\n",
    "        _, j = divmod(_positon, column)\n",
    "        #print(j)\n",
    "        #print(perm_inds_new[j])\n",
    "        if score_new.min() < score:  # minimizing\n",
    "            score = score_new.min()\n",
    "            if self.shuffle_input:\n",
    "                perm_inds = np.array([0] * n)\n",
    "                perm_inds[node_shuffle_input] = perm_inds_new[j]\n",
    "                #print(perm_inds)\n",
    "            else:\n",
    "                perm_inds = perm_inds_new[j]\n",
    "                #print(perm_inds)\n",
    "\n",
    "        \n",
    "\n",
    "        if self.shuffle_input:\n",
    "            node_unshuffle_input = np.array(range(n))\n",
    "            node_unshuffle_input[node_shuffle_input] = np.array(range(n))\n",
    "            A = A[np.ix_(node_unshuffle_input, node_unshuffle_input)]\n",
    "            score = np.trace(np.transpose(A) @ B[np.ix_(perm_inds, perm_inds)])\n",
    "\n",
    "        self.perm_inds_ = perm_inds  # permutation indices\n",
    "        self.score_ = score  # objective function value\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, A, B):\n",
    "        self.fit(A, B)\n",
    "        return self.perm_inds_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9OegmQ_D3n17",
    "outputId": "dbd0614f-4e45-47cc-c7c4-cd56ffe99256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:04:34.542567\n",
      "Number of edge disagreements:  87276.0\n"
     ]
    }
   ],
   "source": [
    "#from par305 import FastApproximateQAP\n",
    "#n_jobs=-1\n",
    "\n",
    "n = 500\n",
    "p = 0.3\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)\n",
    "\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "G2 = G1[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "\n",
    "start = dt.datetime.now()\n",
    "gmp = FastApproximateQAP(n_init=10,init_method=\"rand\",gmp=True)\n",
    "gmp = gmp.fit(G1,G2)\n",
    "G2 = G2[np.ix_(gmp.perm_inds_, gmp.perm_inds_)]\n",
    "print ('running time', dt.datetime.now() - start)\n",
    "\n",
    "print(\"Number of edge disagreements: \", sum(sum(abs(G1-G2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wXvuyHKo3n1-",
    "outputId": "128142c6-f0c4-4197-b94b-3b9a25848322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:36:25.260441\n",
      "Number of edge disagreements:  87432.0\n"
     ]
    }
   ],
   "source": [
    "#from par305 import FastApproximateQAP \n",
    "#n_jobs=-1\n",
    "\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)\n",
    "\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "G2 = G1[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "\n",
    "start = dt.datetime.now()\n",
    "gmp = FastApproximateQAP(n_init=80,init_method=\"rand\",gmp=True)\n",
    "gmp = gmp.fit(G1,G2)\n",
    "G2 = G2[np.ix_(gmp.perm_inds_, gmp.perm_inds_)]\n",
    "print ('running time', dt.datetime.now() - start)\n",
    "\n",
    "print(\"Number of edge disagreements: \", sum(sum(abs(G1-G2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F-Vd2xkU3n2E",
    "outputId": "bb5f095a-6310-415e-b6e6-455239b3a198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time 0:04:37.610873\n",
      "Number of edge disagreements:  87352.0\n"
     ]
    }
   ],
   "source": [
    "# if we set n_jobs=5\n",
    "\n",
    "np.random.seed(1)\n",
    "G1 = er_np(n=n, p=p)\n",
    "\n",
    "node_shuffle_input = np.random.permutation(n)\n",
    "G2 = G1[np.ix_(node_shuffle_input, node_shuffle_input)]\n",
    "\n",
    "start = dt.datetime.now()\n",
    "gmp = FastApproximateQAP(n_init=10,init_method=\"rand\",gmp=True)\n",
    "gmp = gmp.fit(G1,G2)\n",
    "G2 = G2[np.ix_(gmp.perm_inds_, gmp.perm_inds_)]\n",
    "print ('running time', dt.datetime.now() - start)\n",
    "\n",
    "print(\"Number of edge disagreements: \", sum(sum(abs(G1-G2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FhhMcmK3n2K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "withPar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
